{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a4f5277-f9ca-42fb-854e-1f25e1715157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "model = load_model(\"C:/Users/Muhammad Mitkar/Desktop/LSN/gru_language_detection_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "543d95bd-0f8e-42de-a460-c7ea191bef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 100  # Replace with the actual value used during training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92a8e2fe-f69a-41b3-8ab0-572988ef8b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def preprocess_input(input_text):\n",
    "    # Convert input text to the same format as the training data\n",
    "    # Example: Tokenization, padding, or encoding\n",
    "    tokenized_input = tokenizer.texts_to_sequences([input_text])\n",
    "    padded_input = pad_sequences(tokenized_input, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "    return padded_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb2166fe-e26a-45c5-9714-449eecf5adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(input_text):\n",
    "    # Convert input text to the same format as the training data\n",
    "    # Example: Tokenization, padding, or encoding\n",
    "    tokenized_input = tokenizer.texts_to_sequences([input_text])\n",
    "    padded_input = pad_sequences(tokenized_input, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "    return padded_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e12d1c7-10ef-4365-ba8e-f24099d64e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_language(input_text):\n",
    "    preprocessed_input = preprocess_input(input_text)\n",
    "    predictions = model.predict(preprocessed_input)\n",
    "    # Convert prediction to language label (e.g., English, Hindi, etc.)\n",
    "    predicted_language = label_encoder.inverse_transform([np.argmax(predictions)])\n",
    "    return predicted_language[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5108d5be-b91f-42d2-a244-b5cda4102090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
    "import json\n",
    "\n",
    "# Load the tokenizer from the saved JSON file\n",
    "with open(\"C:/Users/Muhammad Mitkar/Desktop/LSN/tokenizer.json\", \"r\") as f:\n",
    "    tokenizer_json = json.load(f)\n",
    "    tokenizer = tokenizer_from_json(tokenizer_json)\n",
    "\n",
    "\n",
    "print(\"Tokenizer loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edae36f6-0f34-4d6d-b092-bbee173737e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the label encoder\n",
    "with open(\"C:/Users/Muhammad Mitkar/Desktop/LSN/label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "print(\"Label encoder loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9abed2-7ef9-4804-8b8a-1badf4bd43e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"زندگی میں کامیابی حاصل کرنے کے لیے صبر، محنت اور مستقل مزاجی کی ضرورت ہوتی ہے، کیونکہ مشکلات اور چیلنجز ہمیں مضبوط اور تجربہ کار بناتے ہیں۔\"\n",
    "predicted_language = predict_language(input_text)\n",
    "print(f\"Input: {input_text}\")\n",
    "print(f\"Predicted Language: {predicted_language}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f457938a-ad5e-4dbe-9f0a-a751999befd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect, detect_langs\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"C:/Users/Muhammad Mitkar/Desktop/LSN/gru_language_detection_model.h5\")\n",
    "\n",
    "# Define the max sequence length (this should match the length used during training)\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "\n",
    "# Load the tokenizer from the saved JSON file\n",
    "with open(\"C:/Users/Muhammad Mitkar/Desktop/LSN/tokenizer.json\", \"r\") as f:\n",
    "    tokenizer_json = json.load(f)\n",
    "    tokenizer = tokenizer_from_json(tokenizer_json)\n",
    "\n",
    "# Load the label encoder\n",
    "with open(\"C:/Users/Muhammad Mitkar/Desktop/LSN/label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "# Preprocessing function: Tokenize and pad the input text\n",
    "def preprocess_input(input_text):\n",
    "    # Tokenize and pad the input text\n",
    "    tokenized_input = tokenizer.texts_to_sequences([input_text])\n",
    "    padded_input = pad_sequences(tokenized_input, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "    return padded_input\n",
    "\n",
    "# Prediction function: Predict the language\n",
    "def predict_language(input_text):\n",
    "    # Preprocess the input text\n",
    "    preprocessed_input = preprocess_input(input_text)\n",
    "    \n",
    "    # Predict using the model\n",
    "    predictions = model.predict(preprocessed_input)\n",
    "    \n",
    "    # Convert predictions to language label using the label encoder\n",
    "    predicted_language = label_encoder.inverse_transform([np.argmax(predictions)])\n",
    "    \n",
    "    return predicted_language[0]\n",
    "\n",
    "# Function to detect language of each sentence and predict languages\n",
    "def predict_multilingual(input_text):\n",
    "    # Split the text into sentences or parts\n",
    "    sentences = input_text.split('.')  # Split by period (or use other logic to split based on punctuation or space)\n",
    "\n",
    "    # Detect the language for each sentence and predict\n",
    "    predictions = []\n",
    "    for sentence in sentences:\n",
    "        if sentence.strip():  # Avoid empty sentences\n",
    "            lang = detect(sentence)  # Detect the language of the sentence\n",
    "            print(f\"Detected Language for '{sentence}': {lang}\")\n",
    "            \n",
    "            predicted_language = predict_language(sentence)  # Predict language for the segment\n",
    "            predictions.append((sentence, predicted_language))\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Example input with mixed languages\n",
    "input_text = \"اگرچہ اسے اپنی زندگی میں بے شمار مشکلات اور ناکامیوں کا سامنا کرنا پڑا، لیکن اس نے کبھی امید کا دامن نہیں چھوڑا اور مسلسل محنت کرتا رہا، اس یقین کے ساتھ کہ ایک دن اس کی لگن اور محنت اسے وہ کامیابی اور خوشی دلائے گی جس کا وہ ہمیشہ خواب دیکھتا تھا۔.I AM MUHAMMAD MITKAR THE BIGEST NOOB EVER EXISITED BECAUSE I AMM LIVING IN THAT PART OF A PLANET. AND I AM DONG THIS FOR SO LONG\"\n",
    "\n",
    "# Get the predicted languages for each segment\n",
    "predictions = predict_multilingual(input_text)\n",
    "\n",
    "# Output the result\n",
    "for sentence, language in predictions:\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Predicted Language: {language}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa6a2a5-8154-41b2-98a1-604e0c65f1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSNENV",
   "language": "python",
   "name": "lsnenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
